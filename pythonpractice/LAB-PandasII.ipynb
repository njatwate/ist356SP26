{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In-Class Coding Lab: Transformations with Pandas\n",
    "\n",
    "This lab will explore some **Stocks** data as retrieved from **Yahoo Finance** in March of 2024. All of the data you will nee can be found in the `stocks` folder where you found this lab.\n",
    "\n",
    "The emphasis of this lab is not data analysis per-se but instad how to deal with complex data sets, specifically:\n",
    "\n",
    " - reading data in JSON format\n",
    " - scraping HTML table data from the web\n",
    " - combining data sets using `concat()`\n",
    " - connecting data sets on a common column using `merge()`\n",
    " - custom operations using `apply()`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_cell_type": "run_code"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from IPython.display import display\n",
    "# this turns off warning messages\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading in JSON data\n",
    "\n",
    "The preferred method of reading in JSON data into a Pandas DataFrame is to deserialize the data with the `json` library and then use `pd.json_normalize()` to further process the data. As we saw in the reading for this week `json_normalize()` is quite powerful for handling the JSON format and has many options.  \n",
    "\n",
    "If you observe the `stocks/company-info.json` file, you will see the JSON is *nested*. For example the `city` key is under the `info` key.\n",
    "\n",
    "```\n",
    "[\n",
    "    {\n",
    "        \"symbol\": \"X\",\n",
    "        \"name\": \"United States Steel Corporation\",\n",
    "        \"exchange\": \"NYQ\",\n",
    "        \"industry\": \"Steel\",\n",
    "        \"sector\": \"Basic Materials\",\n",
    "        \"info\": {\n",
    "            \"website\": \"https://www.ussteel.com\",\n",
    "            \"city\": \"PA\",\n",
    "            \"state\": \"Pittsburgh\",\n",
    "            \"country\": \"United States\"\n",
    "        }\n",
    "    },\n",
    "    ...\n",
    "```\n",
    "\n",
    "`json_normalize()` can handle nested JSON easily. \n",
    "\n",
    "### Why is nested JSON a problem?\n",
    "\n",
    "run this code to read in the `company-info`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "companies = pd.read_json(\"stocks/company-info.json\")\n",
    "companies[['info']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "companies.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See the problem here? the `info` key in the JSON has 4 key-values. These are not accessible as the `read_json()` function does not inspect inside the keys for other nested JSON.\n",
    "\n",
    "This means the values `website`, `city`, `state` and `country` are not accessible. :-(\n",
    "\n",
    "### json_normalize() to the rescue!\n",
    "\n",
    "By default `json_normalize()` will flatten the schema. It takes some extra work because you can't use it from a file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(\"stocks/company-info.json\", \"r\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "companies = pd.json_normalize(data)\n",
    "companies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "companies.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 You Code\n",
    "\n",
    "To demonstrate the nested values are available, use pandas filters to display these columns:\n",
    "\n",
    "    - symbol\n",
    "    - name\n",
    "    - info.state\n",
    "    \n",
    "for only those companies in California `'CA'` as the boolean index.\n",
    "\n",
    "Place the results in a separate dataframe variable and then display it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_cell_type": "write_code",
    "label": "1.1",
    "solution": [
     "query = companies[companies['info.state'] == 'CA'][['symbol', 'name', 'info.state']]\n",
     "query\n"
    ],
    "tags": []
   },
   "outputs": [],
   "source": [
    "# todo write code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple web scraping with Pandas\n",
    "\n",
    "The pandas `read_html(url)` method function allows us to read all the HTML tables on the webpage at the provided `url`. This is a quick a easy method of *web scraping* (parsing content from the web).\n",
    "\n",
    "`read_html()` will return a list of every HTML table on the page. It's then up to us to figure out which one in the list is the one we want. \n",
    "\n",
    "\n",
    "### Example:\n",
    "\n",
    "For example, visit this page in your web browser: [https://en.wikipedia.org/wiki/Display_resolution](https://en.wikipedia.org/wiki/Display_resolution)\n",
    "\n",
    "About 1/2 down the page, there is a section titled **Common Display Resolutions** and within this section there is a data table. Let's capture this table in Pandas using code.\n",
    "\n",
    "This code will read every table on the webpage, making a Python `list`:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tables = pd.read_html(\"https://en.wikipedia.org/wiki/Display_resolution\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's iterate over the tables printing the index and the table itself. This makes it easier to find the table we want from the webpage. To get the index while we loop, we use the `enumerate()` function which returns the item and its index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for index, table in enumerate(tables):\n",
    "    print(\"INDEX:\", index)\n",
    "    print(\"TABLE:\")\n",
    "    display(table.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 18 tables?!?!?\n",
    "\n",
    "That's a lot of tables, but it looks like the table at `index == 4` is the one we want!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "resolutions = tables[4]\n",
    "display(resolutions.head(n=10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have \"discovered\" where the table we want it located, we can tidy our code up as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tables = pd.read_html(\"https://en.wikipedia.org/wiki/Display_resolution\")\n",
    "# we we discovered its at index 4\n",
    "resolutions = tables[4] \n",
    "display(resolutions.head(n=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 You Code \n",
    "\n",
    "Write code to extract the **S&P 500 component stocks** table from this webpage:   \n",
    "\n",
    "`https://en.wikipedia.org/wiki/List_of_S%26P_500_companies` [https://en.wikipedia.org/wiki/List_of_S%26P_500_companies](https://en.wikipedia.org/wiki/List_of_S%26P_500_companies)\n",
    "\n",
    "TIP: Use the cell above this one to \"figure it out\" and once you know the exact code, place it in the cell below. Name the DataFrame variable `sandp`, and use the `display()` function to show a random `sample()` of 10 companies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_cell_type": "write_code",
    "label": "1.2",
    "solution": [
     "tables = pd.read_html('https://en.wikipedia.org/wiki/List_of_S%26P_500_companies')\n",
     "sandp = tables[0]\n",
     "display(sandp.sample(n=10))\n"
    ],
    "tags": []
   },
   "outputs": [],
   "source": [
    "# todo write code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging two DataFrames together on a common/maching column.\n",
    "\n",
    "Right now we have 2 DataFrame sets of data\n",
    "\n",
    "`companies` - our list of companies.  \n",
    "`sandp` - the companies on the S&P 500 index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_cell_type": "run_code"
   },
   "outputs": [],
   "source": [
    "companies.sort_values(\"symbol\").head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_cell_type": "run_code"
   },
   "outputs": [],
   "source": [
    "sandp.sort_values(\"Symbol\").head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that `AAPL` is on both our company list and the S&P500 company list.  Its great to observe that but even better to output it programmatically with code. \n",
    "\n",
    "### Join types\n",
    "\n",
    "For two datasets, in this case:\n",
    "\n",
    "```\n",
    "+===========+                 +===========+\n",
    "| companies |                 |   sandp   |\n",
    "+===========+                 +===========+\n",
    "|   Our     |                 |  S and P  |\n",
    "| Companies |                 | 500 Index |\n",
    "+-----------+                 +-----------+\n",
    "| column:   |                 | column:   | \n",
    "|   symbol  |                 |  Symbol   | \n",
    "+-----------+                 +-----------+\n",
    "```\n",
    "Consider `companies` on the left and `sandp` on the right. Left and right are relative but we need some kind of positioning for reference.\n",
    "\n",
    "Here are the 3 join possibilities `left`, `inner` and `right` along with their results.\n",
    "\n",
    "```\n",
    "+===========+  +===========+  +===========+\n",
    "| how:left  |  | how:inner |  | how:right |\n",
    "+===========+  +===========+  +===========+\n",
    "| RESULTS:  |  | RESULTS:  |  | RESULTS:  |\n",
    "| inner +   |  | only rows |  | inner +   |\n",
    "| all rows  |  | IN BOTH   |  | all rows  |\n",
    "|  from     |  | companies |  |  from     |\n",
    "| companies |  | AND sandp |  | sandp     |\n",
    "+-----------+  +-----------+  +-----------+\n",
    "\n",
    "```\n",
    "\n",
    "So in Summary\n",
    "\n",
    "- `how='inner'` ==> the resulting DataFrame contains only matches from the `left` and `right`\n",
    "- `how='left'` ==> the resulting DataFrame contains all of the `left` + matches from the `left` and `right`\n",
    "- `how='right'` ==> the resulting DataFrame contains all of the `right` + matches from the `left` and `right`\n",
    "\n",
    "### Which companies are not on the S&P 500?\n",
    "\n",
    "Together let's figure out which `companies` are NOT on the `sandp`.\n",
    "\n",
    "This is a two step process:\n",
    "\n",
    "1. `merge()` the dataframes together using a `how='left'`. Because we said `left`, the results will include matches `companies['symbol'] == sandp['Symbol']` in addition to all the rows from `companies` (because its on the left).\n",
    "2. Filter out any rows where the `joined['Symbol'].isna()` because if its `np.nan` that means there was no match.\n",
    "\n",
    "And what remains are companies that are NOT on the S&P 500!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_cell_type": "run_code"
   },
   "outputs": [],
   "source": [
    "# first perform the join\n",
    "joined = pd.merge(left=companies, right=sandp, how=\"left\", left_on=\"symbol\", right_on=\"Symbol\")\n",
    "\n",
    "# second filter out any of the matches\n",
    "not_on_sandp = joined[joined[\"Symbol\"].isna()]\n",
    "not_on_sandp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 You Code\n",
    "\n",
    "Now you try it use the `merge()` method function to join the `companies` to `sandp` but this time only show matches. If you use a different `how` you can complete this in a single step.\n",
    "\n",
    "Save the results in a `matched` dataframe and `display()` it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_cell_type": "write_code",
    "label": "1.3",
    "solution": [
     "matched = pd.merge(left=companies, right=sandp, how='inner', left_on='symbol', right_on='Symbol')\n",
     "display(matched)\n"
    ],
    "tags": []
   },
   "outputs": [],
   "source": [
    "# todo write code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining DataFrames by row.\n",
    "\n",
    "We can use the `concat()` method function to combine rows of multiple dataframes into a single dataframe with more rows.\n",
    "\n",
    "For example if you `contact()` three dataframes with 10, 15 and 20 rows the resulting dataframe will have 10+15+20 == 45 rows.\n",
    "\n",
    "In this example we read in stock history for the 3 companies in the list, and append them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "microsoft = pd.read_csv(\"stocks/MSFT.csv\")\n",
    "microsoft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "google = pd.read_csv(\"stocks/GOOG.csv\")\n",
    "google"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "apple = pd.read_csv(\"stocks/AAPL.csv\")\n",
    "apple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "combined = pd.concat([microsoft, google, apple], ignore_index=True)\n",
    "combined"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice to use `concat()` the target dataframes must be in a list.\n",
    "\n",
    "### 1.4 You Code\n",
    "\n",
    "Let's make the previous example more efficient by using a loop. Most of this code has been written for you. You just need to write the one line of code to read in each stock inside the body of the loop.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_cell_type": "write_code",
    "label": "1.4",
    "solution": [
     "stocks = ['MSFT', 'GOOG', 'AAPL']\n",
     "combined = pd.DataFrame()\n",
     "for stock in stocks:\n",
     "    filename = f'stocks/{stock}.csv'\n",
     "    # todo read the filename into `stocks_df\n`",
     "    stocks_df = pd.read_csv(filename)\n",
     "    combined = pd.concat([combined, stocks_df], ignore_index=True)\n",
     "combined\n"
    ],
    "solution_threshold": 0,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# todo: repeat the analysis in the previous cell for Pclass \n",
    "stocks = [\"MSFT\", \"GOOG\", \"AAPL\"]\n",
    "combined = pd.DataFrame()\n",
    "for stock in stocks:\n",
    "    filename = f\"stocks/{stock}.csv\"\n",
    "    # todo read the filename into `stocks_df`\n",
    "\n",
    "    combined = pd.concat([combined, stocks_df], ignore_index=True)\n",
    "combined"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lambdas and apply()\n",
    "\n",
    "The Pandas `apply()` method allows us to write a user-defined function and the invoke that function for every row in the dataframe.\n",
    "\n",
    "This is useful when you need to implement complex transformational logic on your dataframes.\n",
    "\n",
    "### Example\n",
    "\n",
    "Let's predend there is an applied tax rate based on the `info.state` based on the following table:\n",
    "\n",
    "    - NY = 0.15\n",
    "    - WA = 0.10\n",
    "    - CA = 0.20\n",
    "    - Tx = 0.05\n",
    "    - Everyone else = 0.0\n",
    "\n",
    "We've seen before you can write this as a function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def taxrate(state: str) -> float:\n",
    "    state = state.upper()\n",
    "    if state == \"NY\":\n",
    "        rate = 0.15\n",
    "    elif state == \"WA\":\n",
    "        rate = 0.1 \n",
    "    elif state == 'CA':\n",
    "        rate = 0.2\n",
    "    elif state == 'TX':\n",
    "        rate = 0.05\n",
    "    else:\n",
    "        rate = 0.0\n",
    "    return rate\n",
    "\n",
    "# simple test\n",
    "assert taxrate(\"TX\") == 0.05"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the function created we can now use `apply()` to calculate a `\"tax\"` column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "companies[\"tax\"] = companies.apply(lambda row: taxrate(row[\"info.state\"]), axis=1)\n",
    "companies.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### NOTE!!!\n",
    "\n",
    "For more details on `lambda/apply` check the assigned reading!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def change(open: float, close: float) -> float:\n",
    "    return close - open\n",
    "\n",
    "assert change(1.5, 1.25) == -0.25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 You Code \n",
    "\n",
    "Using the function `change()` as defined in the cell above, add a column to the `combined` dataframe from 1.4 called `\"change\"` which calculates the change in the stock for each row. `display()` the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_cell_type": "write_code",
    "label": "1.5",
    "solution": [
     "combined['change'] = combined.apply(lambda row: change(row['Open'], row['Close']), axis =1)\n",
     "display(combined)\n"
    ],
    "tags": []
   },
   "outputs": [],
   "source": [
    "# todo write code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metacognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Rate your comfort level with this week's material so far.   \n",
    "\n",
    "**1** ==> I don't understand this at all yet and need extra help. If you choose this please try to articulate that which you do not understand to the best of your ability in the questions and comments section below.  \n",
    "**2** ==> I can do this with help or guidance from other people or resources. If you choose this level, please indicate HOW this person helped you in the questions and comments section below.   \n",
    "**3** ==> I can do this on my own without any help.   \n",
    "**4** ==> I can do this on my own and can explain/teach how to do it to others.\n",
    "\n",
    "`ENTER A NUMBER 1-4 IN THE CELL BELOW`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "label": "comfort_cell",
    "tags": []
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "###  Questions And Comments \n",
    "\n",
    "Record any questions or comments you have about this lab that you would like to discuss in your recitation. It is expected you will have questions if you  complete this assignment.  Learning how to articulate what you do not understand is an important skill of critical thinking. Write your questions below so that you remember to ask them in your recitation. We expect you will take responsilbity for your learning and ask questions in class.\n",
    "\n",
    "`ENTER YOUR QUESTIONS/COMMENTS IN THE CELL BELOW`  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "label": "question_cell",
    "tags": []
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Turn it In\n",
    "\n",
    "FIRST AND FOREMOST: **Save Your work!** Yes, it auto-saves, but you should get in the habit of saving before submitting. From the menu, choose File --> Save Notebook. Or you can use the shortcut keys `CTRL+S`\n",
    "\n",
    "### First: Lab Check\n",
    "\n",
    "Check your lab before submitting. Look for errors and incomplete parts which might cost you a better grade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ Not all code cells were executed.\n",
      "❌ Comfort level is blank.\n",
      "❌ Questions cell is blank. You should have a question or comment.\n",
      "❌ 1.1 you code does not have a code solution.\n",
      "❌ 1.2 you code does not have a code solution.\n",
      "❌ 1.3 you code does not have a code solution.\n",
      "❌ 1.5 you code does not have a code solution.\n"
     ]
    }
   ],
   "source": [
    "from casstools.notebook_tools import NotebookFile\n",
    "NotebookFile().check_lab()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second: Lab Submission\n",
    "\n",
    "Run this code and follow the instructions to turn in your lab. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ TIMESTAMP  : 2025-04-09 11:50\n",
      "✅ COURSE     : ist256\n",
      "✅ TERM       : spring2025\n",
      "✅ USER       : mafudge@syr.edu\n",
      "✅ STUDENT    : True\n",
      "✅ PATH       : ist256/spring2025/lessons/11-Pandas-II/LAB-PandasII.ipynb\n",
      "✅ ASSIGNMENT : LAB-PandasII.ipynb\n",
      "✅ POINTS     : 3\n",
      "✅ DUE DATE   : 2025-04-08 23:59\n",
      "✅ LATE       : True\n",
      "✅ STATUS     : New Submission\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "❓ Assignment is late. Submit? [y/n] ❓  y\n"
     ]
    }
   ],
   "source": [
    "from casstools.assignment import Assignment\n",
    "Assignment().submit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": false,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
